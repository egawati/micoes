{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from river import anomaly\n",
    "from river import compose\n",
    "from river import datasets\n",
    "from river import metrics\n",
    "from river import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From skmultiflow/river documentation:\n",
    "> Half-space trees (HST) are an online variant of isolation forests. They work well when anomalies are\n",
    "    spread out. However, they do not work well if anomalies are packed together in windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress, product\n",
    "def combinations(items):\n",
    "    return (set(compress(items,mask)) for mask in product(*[[0,1]]*len(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hst_score(x, model, attributes, y=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x \n",
    "        a list or a numpy array\n",
    "    y\n",
    "        None\n",
    "        0 for normal data\n",
    "        1 for outlier\n",
    "    \"\"\"\n",
    "    features = dict(zip(attributes, x))\n",
    "    score = model.score_one(features)\n",
    "    \n",
    "    if y is None:\n",
    "        model = model.learn_one(features)\n",
    "    else:\n",
    "        model = model.learn_one(features, y)\n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hst_score_for_every_subspace(df, epoch=2, label='label', window_size=60):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df\n",
    "        pandas dataframe\n",
    "    \"\"\"\n",
    "    if label:\n",
    "        Y = df[label]\n",
    "        df = df.drop(label, axis=1)\n",
    "    else:\n",
    "        Y = None\n",
    "        \n",
    "    attribute_subsets = list(combinations(df.columns))\n",
    "    scores_dict = {}\n",
    "    logging.info(f'Total attribute spaces {len(attribute_subsets)}')\n",
    "    check = 0\n",
    "    for attributes in attribute_subsets:\n",
    "        check += 1\n",
    "        logging.info(f'Working on the {check}-attribute space')\n",
    "        if not attributes:\n",
    "            continue\n",
    "        X = df[list(attributes)].values\n",
    "        model = compose.Pipeline(\n",
    "                preprocessing.MinMaxScaler(),\n",
    "                anomaly.HalfSpaceTrees(seed=1, window_size=window_size)\n",
    "            )\n",
    "        for _ in range(epoch):\n",
    "            i = 0\n",
    "            scores = list()\n",
    "            for x in X:\n",
    "                if Y is not None:\n",
    "                    score, model = compute_hst_score(x, model, list(attributes), y=Y[i])\n",
    "                    i += 1\n",
    "                else:\n",
    "                    score, model = compute_hst_score(x, model, list(attributes))\n",
    "                scores.append(score)\n",
    "        scores_dict[tuple(attributes)] = scores\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_scores_dictionary(scores_dict1, scores_dict2):\n",
    "    ds = [scores_dict1, scores_dict2]\n",
    "    scores_dict = {}\n",
    "    for key in scores_dict1.keys():\n",
    "        scores_dict[key] = scores_dict1[key] + scores_dict2\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hst_score(scores_dict, object_id):\n",
    "    \"\"\"\n",
    "    get hst scores for an object in every combinations of attribute. \n",
    "    order the attribute space based on the hst score in descending order\n",
    "    \"\"\"\n",
    "    object_scores = {}\n",
    "    for key, value in scores_dict.items():\n",
    "        new_key = ', '.join(key)\n",
    "        object_scores[key] = value[object_id]\n",
    "    object_ordered_dict = OrderedDict(sorted(object_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "    return object_ordered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlying_attributes(object_ordered_dict, num=1, score=False):\n",
    "    \"\"\"\n",
    "    get list of the outlying attribute space\n",
    "    example :\n",
    "        >> get_outlying_attributes(object_ordered_dict)\n",
    "        >> ['petal width (cm)']\n",
    "        >> get_outlying_attributes(object_ordered_dict, num=2, score=True)\n",
    "        >> [('petal width (cm)', 0.9964180039138943),\n",
    "            ('petal length (cm), petal width (cm)', 0.9964180039138943)]\n",
    "        \n",
    "    \"\"\"\n",
    "    if not score:\n",
    "        keys = list(object_ordered_dict.keys())[:num]\n",
    "        return keys\n",
    "    else:\n",
    "        items = list(object_ordered_dict.items())[:num]\n",
    "        return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_outlying_attribute_hst(df, label, num=1, score=False, epoch=2, remove_col_1=True, outlier_target=1, window_size=60):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath\n",
    "        string, filepath of csv file containing information whether a tuple/object is an outlier (1) or not (0)\n",
    "    label\n",
    "        string, the column that indicates whether a tuple/object is an outlier (1) or not (0)\n",
    "    num\n",
    "        int, number of outlying attribute to find\n",
    "    score:\n",
    "        bool, to determine whether to return hst outlier scores or not\n",
    "    epoch:\n",
    "        int, number of iteration needed to train the hst model\n",
    "    \"\"\"\n",
    "    if remove_col_1:\n",
    "        df = df.drop(df.columns[[0]], axis=1)\n",
    "    outlier_indices = list(np.where(df[label] == 1)[0])\n",
    "    \n",
    "    scores_dict = compute_hst_score_for_every_subspace(df, epoch, label, window_size)\n",
    "    \n",
    "    outlying_attributes = list() \n",
    "    for i in outlier_indices:\n",
    "        object_ordered_dict = get_hst_score(scores_dict, i)\n",
    "        outlying_attribute = get_outlying_attributes(object_ordered_dict, num, score)\n",
    "        outlying_attributes.append(outlying_attribute)\n",
    "    results = {}\n",
    "    results['outlier_indices'] = outlier_indices\n",
    "    results['outlying_attributes'] = outlying_attributes\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NumExpr defaulting to 8 threads.\n",
      "Total attribute spaces 16\n",
      "Working on the 1-attribute space\n",
      "Working on the 2-attribute space\n",
      "Working on the 3-attribute space\n",
      "Working on the 4-attribute space\n",
      "Working on the 5-attribute space\n",
      "Working on the 6-attribute space\n",
      "Working on the 7-attribute space\n",
      "Working on the 8-attribute space\n",
      "Working on the 9-attribute space\n",
      "Working on the 10-attribute space\n",
      "Working on the 11-attribute space\n",
      "Working on the 12-attribute space\n",
      "Working on the 13-attribute space\n",
      "Working on the 14-attribute space\n",
      "Working on the 15-attribute space\n",
      "Working on the 16-attribute space\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('sepal length (cm)', 'petal width (cm)'), ('sepal length (cm)',)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "def example_3():\n",
    "    iris = datasets.load_iris()\n",
    "    iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                         columns= iris['feature_names'] + ['target'])\n",
    "    setosa = iris_df[iris_df['target'] == 0.0]\n",
    "    versicolor = iris_df[iris_df['target'] == 1.0]\n",
    "    virginica = iris_df[iris_df['target'] == 2.0]\n",
    "    row_df = pd.DataFrame([versicolor.iloc[0], virginica.iloc[0]])\n",
    "    df = pd.concat([setosa, row_df], ignore_index=True)\n",
    "    df[\"target\"].replace({0.0: int(0), 1.0: int(1), 2.0 : int(1)}, inplace=True)\n",
    "    scores_dict = compute_hst_score_for_every_subspace(df, epoch=2, label='target')\n",
    "    object_50 = get_hst_score(scores_dict,50)\n",
    "    object_51 = get_hst_score(scores_dict,51)\n",
    "    return object_50, object_51\n",
    "object_50, object_51 = example_3()\n",
    "get_outlying_attributes(object_50, num=2, score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_matlab_data_file(filepath):\n",
    "    mat = sio.loadmat(filepath)\n",
    "    columns = [f'A{i+1}' for i in range(mat['X'].shape[1])]\n",
    "    df = pd.DataFrame(data=mat['X'], columns=columns)\n",
    "    df['label'] = mat['y']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_matlab_data_with_h5py(filepath):\n",
    "    mat = {}\n",
    "    f = h5py.File(filepath)\n",
    "    for k, v in f.items():\n",
    "        mat[k] = np.array(v)\n",
    "    columns = [f'A{i+1}' for i in range(mat['X'].shape[0])]\n",
    "    df = pd.DataFrame(data=mat['X'].T, columns=columns)\n",
    "    df['label'] = mat['y'].T\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def http(window_size):\n",
    "    filepath = r'../data/odds/http.mat'\n",
    "    df = read_matlab_data_with_h5py(filepath)\n",
    "    logging.info(df.shape)\n",
    "    result = generate_outlying_attribute_hst(df, label='label', num=2, score=False, \n",
    "                                             epoch=2, remove_col_1=False, outlier_target=1,\n",
    "                                             window_size=window_size)\n",
    "    return result\n",
    "# result = http(window_size=60)\n",
    "# result.to_pickle('pickles/http_60.pckle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smtp(window_size):\n",
    "    filepath = r'../data/odds/smtp.mat'\n",
    "    df = read_matlab_data_with_h5py(filepath)\n",
    "    logging.info(df.shape)\n",
    "    result = generate_outlying_attribute_hst(df, label='label', num=2, score=False, \n",
    "                                             epoch=2, remove_col_1=False, outlier_target=1,\n",
    "                                             window_size=window_size)\n",
    "    return result\n",
    "# result = smtp(window_size=60)\n",
    "# result.to_pickle('pickles/smtp_60.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mammography(window_size):\n",
    "    filepath = r'../data/odds/mammography.mat'\n",
    "    df = read_matlab_data_file(filepath)\n",
    "    logging.info(df.shape)\n",
    "    result = generate_outlying_attribute_hst(df, label='label', num=2, score=False, \n",
    "                                             epoch=2, remove_col_1=False, outlier_target=1,\n",
    "                                             window_size=window_size)\n",
    "    return result\n",
    "# result = mammography(window_size=60)\n",
    "# result.to_pickle('pickles/mammography_60.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuttle(window_size):\n",
    "    filepath = r'../data/odds/shuttle.mat'\n",
    "    df = read_matlab_data_file(filepath)\n",
    "    logging.info(df.shape)\n",
    "    result = generate_outlying_attribute_hst(df, label='label', num=2, score=False, \n",
    "                                             epoch=2, remove_col_1=False, outlier_target=1,\n",
    "                                             window_size=window_size)\n",
    "    return result\n",
    "# result = shuttle(window_size=60)\n",
    "# result.to_pickle('pickles/shuttle_60.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(6870, 17)\n",
      "total attribute combinations 65535\n"
     ]
    }
   ],
   "source": [
    "filepath = r'../data/odds/pendigits.mat'\n",
    "df = read_matlab_data_file(filepath)\n",
    "logging.info(df.shape)\n",
    "df = df.drop('label', axis=1)\n",
    "df.columns\n",
    "attribute_space = combinations(df.columns)\n",
    "logging.info(f'total attribute combinations {len(list(attribute_space))-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wine(window_size):\n",
    "    filepath = r'../data/odds/wine.mat'\n",
    "    df = read_matlab_data_file(filepath)\n",
    "    logging.info(df.shape)\n",
    "    result = generate_outlying_attribute_hst(df, label='label', num=2, score=False, \n",
    "                                             epoch=2, remove_col_1=False, outlier_target=1,\n",
    "                                             window_size=window_size)\n",
    "    return result\n",
    "# result = wine(window_size=60)\n",
    "# result.to_pickle('pickles/wine_60.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
